# Hand Proximity Detection â€“ Real-Time OpenCV POC

This project is a real-time Hand Tracking + Virtual Boundary Proximity Alert System, built without MediaPipe, OpenPose, or any pose-detection APIs.
It demonstrates classical computer vision techniques to detect the hand, measure distance to a virtual object, and classify interaction states as:
	â€¢	SAFE
	â€¢	WARNING
	â€¢	DANGER (with on-screen â€œDANGER DANGERâ€)

This prototype is created as part of the Arvyax Internship Assignment.

â¸»

ðŸ“Œ Features

1. Real-Time Hand Tracking (Without ML Models)

Hand tracking is performed purely using:
	â€¢	Skin-color segmentation (HSV color space)
	â€¢	Contour detection
	â€¢	Contour centroid tracking
	â€¢	Noise reduction (Gaussian blur, erosion, dilation)

2. Virtual Object on Screen

The user selects a Region of Interest (ROI) manually using a mouse.
This ROI becomes the virtual object whose center is used to calculate distance.

3. Distance-Based State Logic

The system dynamically assigns one of three states:
	â€¢	SAFE â†’ Hand is far (>120px)
	â€¢	WARNING â†’ Hand approaching (between 60px and 120px)
	â€¢	DANGER â†’ Hand touching or extremely close (<60px)

4. Visual Feedback Overlay

The screen shows:
	â€¢	State (SAFE / WARNING / DANGER)
	â€¢	Distance in pixels
	â€¢	Virtual object highlighted in state-color
	â€¢	Hand contour
	â€¢	Hand center point
	â€¢	â€œDANGER DANGERâ€ flashing on the screen in Danger range

5. CPU-Friendly & Lightweight
	â€¢	Runs at 10â€“20 FPS on standard CPU
	â€¢	Uses only OpenCV + NumPy


ðŸ“‚ Project Structure

Hand_Proximity_POC/
â”‚â”€â”€ hand_proximity.py        # Main code (hand tracking + state logic)
â”‚â”€â”€ Using_LLM_Model.ipynb    # (Optional) ML-based version
â”‚â”€â”€ Without_using_ML.ipynb   # Classical CV version
â”‚â”€â”€ sample_output.png        # Demo image (optional)
â”‚â”€â”€ README.md                # Project documentation


ðŸ“¦ Requirements
Install dependencies:
pip install opencv-python numpy


â–¶ï¸ Run the Project
python hand_proximity.py


Steps during execution:
	1.	Webcam starts
	2.	A window pops up â†’ Select the virtual object using your mouse
	3.	Hand tracking starts automatically
	4.	Approach the object to trigger:
	â€¢	Warning
	â€¢	Danger
	â€¢	â€œDANGER DANGERâ€ alert


ðŸ§  Technical Approach (Short Summary)

The system uses classical computer vision for hand tracking:

Skin Segmentation:

Hand pixels are extracted using HSV color range:
lower = np.array([0, 30, 60])
upper = np.array([20, 150, 255])

Contour Extraction:
Largest contour is considered the hand.

Centroid Calculation:
Hand center = Moments of contour.

Distance Calculation:
Between hand center and virtual object center
dist = np.linalg.norm(hand_center - obj_center)


State Machine
Simple 3-level rule-based system:
dist > 120 â†’ SAFE  
60 < dist â‰¤ 120 â†’ WARNING  
dist â‰¤ 60 â†’ DANGER  
